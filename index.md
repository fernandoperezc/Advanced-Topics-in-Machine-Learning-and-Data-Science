# Objective

In this seminar, recent papers of the machine learning and data science literature are presented and discussed. Possible topics cover statistical models, machine learning algorithms and its applications.

The seminar “Advanced Topics in Machine Learning and Data Science” familiarizes students with recent developments in machine learning and data science. Recently published articles, as well as influential papers, have to be presented and critically reviewed. The students will learn how to structure a scientific presentation, which covers the motivation, key ideas and main results of a scientific paper. An important goal of the seminar presentation is to summarize the essential ideas of the paper in sufficient depth for the audience to be able to follow its main conclusion, especially why the article is (or is not) worth attention. The presentation style will play an important role and should reach the level of professional scientific presentations.

## List of papers:

*   [Integer Discrete Flows and Lossless Compression.](https://papers.nips.cc/paper/9383-integer-discrete-flows-and-lossless-compression.pdf)
*   [Universal Domain Adaptation.](http://openaccess.thecvf.com/content_CVPR_2019/papers/You_Universal_Domain_Adaptation_CVPR_2019_paper.pdf)
*   [Asymmetric Tri-training for Unsupervised Domain Adaptation.](https://arxiv.org/pdf/1702.08400.pdf)
*   [Adaptive and Safe Bayesian Optimization in High Dimensions via One-Dimensional Subspaces.](https://arxiv.org/pdf/1902.03229.pdf)
*   [Combinatorial Bayesian Optimization using the Graph Cartesian Product.](http://papers.nips.cc/paper/8557-combinatorial-bayesian-optimization-using-the-graph-cartesian-product.pdf)
*   [Variational Inference: A Review for Statisticians.](https://amstat.tandfonline.com/doi/full/10.1080/01621459.2017.1285773#.XiGPCjMo_ds)
*   [Variational Bayes under Model Misspecification.](http://papers.nips.cc/paper/9492-variational-bayes-under-model-misspecification.pdf)
*   [Uniform convergence may be unable to explain generalization in deep learning.](http://papers.nips.cc/paper/9336-uniform-convergence-may-be-unable-to-explain-generalization-in-deep-learning.pdf)
*   [In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning.](https://arxiv.org/pdf/1412.6614.pdf)
*   [The Role of Over-Parametrization in Generalization of Neural Networks.](https://openreview.net/pdf?id=BygfghAcYX)
*   [Fairness Constraints: Mechanisms for Fair Classification.](https://arxiv.org/pdf/1507.05259.pdf)
*   [Overparameterized Neural Networks Can Implement Associative Memory.](https://arxiv.org/pdf/1909.12362.pdf)
*   [Prescribed Generative Adversarial Networks.](https://arxiv.org/pdf/1910.04302.pdf)
*   [Federated Optimization: Distributed Machine Learning for On-Device Intelligence.](https://arxiv.org/pdf/1610.02527.pdf)
*   [Differentially Private Regression with Gaussian Processes.](http://proceedings.mlr.press/v84/smith18a/smith18a.pdf)
*   [A Fast Learning Algorithm for Deep Belief Nets.](https://www.mitpressjournals.org/doi/pdfplus/10.1162/neco.2006.18.7.1527)
*   [Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks.](https://arxiv.org/pdf/1810.00825.pdf)
*   [Geometric Deep Learning: Going beyond Euclidean data.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974879)
*   [Gaussian Process Behaviour in Wide Deep Neural Networks.](https://arxiv.org/pdf/1804.11271.pdf)
*   [A Kernel Two-Sample Test.](http://www.jmlr.org/papers/volume13/gretton12a/gretton12a.pdf)



