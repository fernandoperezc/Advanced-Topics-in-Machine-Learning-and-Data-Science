# Objective

In this seminar, recent papers of the machine learning and data science literature are presented and discussed. Possible topics cover statistical models, machine learning algorithms and its applications.

The seminar “Advanced Topics in Machine Learning and Data Science” familiarizes students with recent developments in machine learning and data science. Recently published articles, as well as influential papers, have to be presented and critically reviewed. The students will learn how to structure a scientific presentation, which covers the motivation, key ideas and main results of a scientific paper. An important goal of the seminar presentation is to summarize the essential ideas of the paper in sufficient depth for the audience to be able to follow its main conclusion, especially why the article is (or is not) worth attention. The presentation style will play an important role and should reach the level of professional scientific presentations.

## Contact:

[Fernando Perez-Cruz](mailto:fernando.perezcruz@sdsc.ethz.ch)

Office TUR E21

## Lectures:

Wednesday 16:00 -- 18:00     LFW  E13

## List of papers:

*   [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.](https://arxiv.org/abs/1406.1078)
*   [Generative Adversarial Networks.](https://arxiv.org/abs/1406.2661)
*   [Effective Approaches to Attention-based Neural Machine Translation.](https://arxiv.org/abs/1508.04025)
*   [Auto-Encoding Variational Bayes.](https://arxiv.org/abs/1312.6114)
*   [Exploring the Limits of Language Modeling.](https://arxiv.org/abs/1602.02410)
*   [Glow: Generative Flow with Invertible 1x1 Convolutions](https://arxiv.org/abs/1807.03039)
*   [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
*   [Deep Unsupervised Learning using Nonequilibrium Thermodynamics.](https://arxiv.org/abs/1503.03585)
*   [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
*   [Generating Diverse High-Fidelity Images with VQ-VAE-2](https://arxiv.org/abs/1906.00446)
*   [Improving Language Understanding by Generative Pre-Training.](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)
*   [Integer Discrete Flows and Lossless Compression](https://arxiv.org/abs/1905.07376)
*   [Language models are few-shot learners.](https://arxiv.org/abs/2005.14165)
*   [Generative Modeling by Estimating Gradients of the Data Distribution](https://arxiv.org/abs/1907.05600)
*   [TruthfulQA: Measuring How Models Mimic Human Falsehoods.](https://aclanthology.org/2022.acl-long.229/)
*   [Denoising Diffusion Probabilistic Models.](https://arxiv.org/abs/2006.11239)
*   [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
*   [Do Deep Generative Models Know What They Don't Know?.](https://arxiv.org/abs/1810.09136)
*   [Vector-quantized Image Modeling with Improved VQGAN.](https://arxiv.org/abs/2110.04627)
*   [Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality.](https://arxiv.org/abs/1906.02994)

## Schedule:

- Feb 22nd: No Lecture
- March 1st: [Introduction](ATMLDS.pdf)
- March 8th: No lecture
- March 15th:
  - Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation by Andrea Pinto.
  - Generative Adversarial Networks by Shubham Chowdhary.
- March 22nd:
  - Effective Approaches to Attention-based Neural Machine Translation by Weronika Ormaniec.
  - Auto-Encoding Variational Bayes by Giulio Vittorio Carassai.
- March 29th: 
  - Exploring the Limits of Language Modeling by Gabriel Gavrilas.
  - Glow: Generative Flow with Invertible 1x1 Convolutions by Arthur Colette.
- April 5th: No lecture
- April 12th (Easter): No lecture
- April 19th:
  -  Attention Is All You Need by Alexander Eichhorn.
  -  Deep Unsupervised Learning using Nonequilibrium Thermodynamics by Josep Borrell Tatche.
- April 26th:
  -  BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Chuhao Feng.
  -  Generating Diverse High-Fidelity Images with VQ-VAE-2 by Jingyu Wang.
- May 3rd:
  -  Improving Language Understanding by Generative Pre-Training by Yunying Zhu.
  -  Integer Discrete Flows and Lossless Compression by Elif Emanet. 
- May 10th:
  -  Language models are few-shot learners by Giovanni Acampa.
  -  Generative Modeling by Estimating Gradients of the Data Distribution by Francesc Marti Escofet.
- May 17th:
  -  TruthfulQA: Measuring How Models Mimic Human Falsehoods by Jan Tempus.
  -  Denoising Diffusion Probabilistic Models by Yiting Qian.
- May 24th:
  -  An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dustin Brunner.
  -  Do Deep Generative Models Know What They Don't Know? by Rongxing Liu.
- May 31st:
  -  Vector-quantized Image Modeling with Improved VQGAN by TBD
  -  Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality by Dion Hopkinson-Sibley

